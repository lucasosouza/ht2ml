{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea of how temporal memory would work\n",
    "\n",
    "# get an input, which is a set of distributed representations\n",
    "# note - use SDR to convert MNITS to distributed representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from data_loader import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10000, 10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call data loader previously to create datasets\n",
    "train, val, test = load_data(n=10)\n",
    "len(train[1]), len(val[1]), len(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.5       , 0.99609375, 0.99609375, 0.25      , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0][200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 9, 1, 3, 6, 9, 2, 6, 8]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retesting pooler approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pooler import *\n",
    "\n",
    "clf = Classifier()\n",
    "clf.learn(train)\n",
    "\n",
    "val_acc = clf.get_accuracy(val)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can I use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train[0][4]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123044f28>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(80), tensor(1, dtype=torch.uint8), tensor(0, dtype=torch.uint8))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't need the classifier, all its doing is building unions\n",
    "pooler = SpatialPooler()\n",
    "sdr = pooler.forward(img)\n",
    "torch.sum(sdr), torch.max(sdr), torch.min(sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sequence of mnist digits represented as sdrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 10, (784,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a sequence to be passed into temporal memory\n",
    "labels = []\n",
    "inputs = []\n",
    "not_complete, num = False, 0\n",
    "while True:\n",
    "    # find one sample of each\n",
    "    for idx, label in enumerate(test[1]):\n",
    "        if label == num:\n",
    "            inputs.append(test[0][idx])\n",
    "            labels.append(test[1][idx]) # just a sanity check\n",
    "            num += 1\n",
    "            break\n",
    "    # only goes to 9\n",
    "    if num == 10:\n",
    "        break\n",
    "\n",
    "labels, len(inputs), inputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44f03e231acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "x = inputs[0]; x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pooler import *\n",
    "pooler = SpatialPooler()\n",
    "indices = pooler.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.3056, 0.3440, 1.1147, 1.3717, 1.3713, 1.5071, 1.3682, 0.6897, 0.8790,\n",
       "        1.9509]),\n",
       "indices=tensor([8, 6, 2, 9, 4, 3, 1, 7, 3, 0]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permanences = torch.randn(10,10)\n",
    "torch.max(permanences, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(10,10) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a second layer 100 columns, 10 cells per column\n",
    "memory = torch.randn((100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(range(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t.view(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48, 49, 50]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 55, 155, 255, 355, 455, 555, 655, 755, 855, 955])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(t2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
       "        [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
       "        [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
       "        [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
       "        [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
       "        [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
       "        [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
       "        [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
       "        [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
       "        [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
       "        [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
       "        [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
       "        [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
       "        [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
       "        [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
       "        [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
       "        [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
       "        [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
       "        [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[1, 9] = 20\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val, indices = torch.topk(t2, 1)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10],\n",
       "        [ 20],\n",
       "        [ 30],\n",
       "        [ 40],\n",
       "        [ 50],\n",
       "        [ 60],\n",
       "        [ 70],\n",
       "        [ 80],\n",
       "        [ 90],\n",
       "        [100]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
       "        [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
       "        [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
       "        [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
       "        [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
       "        [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
       "        [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
       "        [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
       "        [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
       "        [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, indices = torch.topk(t2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10,   9,   8],\n",
       "        [ 20,  19,  18],\n",
       "        [ 30,  29,  28],\n",
       "        [ 40,  39,  38],\n",
       "        [ 50,  49,  48],\n",
       "        [ 60,  59,  58],\n",
       "        [ 70,  69,  68],\n",
       "        [ 80,  79,  78],\n",
       "        [ 90,  89,  88],\n",
       "        [100,  99,  98]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7],\n",
       "        [9, 8, 7]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() received an invalid combination of arguments - got (Tensor, int, Tensor), but expected one of:\n * (Tensor input, int dim, Tensor index, Tensor src)\n * (Tensor input, int dim, Tensor index, Number value)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-fc1125f89550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: scatter() received an invalid combination of arguments - got (Tensor, int, Tensor), but expected one of:\n * (Tensor input, int dim, Tensor index, Tensor src)\n * (Tensor input, int dim, Tensor index, Number value)\n"
     ]
    }
   ],
   "source": [
    "torch.scatter(t2, 2, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, indices = torch.kthvalue(t2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 10]' is invalid for input of size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c603e5f50f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 10]' is invalid for input of size 10"
     ]
    }
   ],
   "source": [
    "vals.view(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [13],\n",
       "        [23],\n",
       "        [33],\n",
       "        [43],\n",
       "        [53],\n",
       "        [63],\n",
       "        [73],\n",
       "        [83],\n",
       "        [93]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 > vals.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val > 10).float().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better to do using masks\n",
    "# more intuitive to undertan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.view(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pooler import TemporalPooler\n",
    "pooler = TemporalPooler(input_size=3, num_columns=4, k_percent=0.4, num_cells=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3756, 0.0000, 0.0000, 0.7734],\n",
       "        [0.4944, 0.3294, 0.4092, 0.0000]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input size 3, num columns 4\n",
    "pooler.proximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.2164, 0.0000, 0.0000, 0.0000, 0.5281, 0.4638],\n",
       "        [0.4559, 0.0000, 0.6079, 0.0000, 0.0000, 0.4573, 0.0000, 0.0000],\n",
       "        [0.4433, 0.3906, 0.0000, 0.0000, 0.6121, 0.6561, 0.0000, 0.5248],\n",
       "        [0.5835, 0.0000, 0.0000, 0.0000, 0.0000, 0.5094, 0.4238, 0.3544],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6286, 0.0000, 0.6196],\n",
       "        [0.5780, 0.0000, 0.0000, 0.6755, 0.3939, 0.0000, 0.0000, 0.5605],\n",
       "        [0.5663, 0.0000, 0.0000, 0.0000, 0.6157, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6246, 0.4775, 0.0000]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooler.distal # num columns 4, num cells 2, 8x8 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "inputs = [[0,0,1], [1,1,0], [0,0,0], [1,1,1]]\n",
    "inputs = [torch.tensor(i) for i in inputs]\n",
    "\n",
    "for i in inputs:\n",
    "    a,b,c = pooler.forward(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pooler import TemporalPooler\n",
    "pooler = TemporalPooler(input_size=3, num_columns=4, k_percent=0.6, num_cells=2)\n",
    "input_sdr = torch.tensor([1, 1, 1])\n",
    "self = pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proximal input size 3, num columns 4\n",
    "# num columns 4, num cells 2, 8x8 matrix\n",
    "spatial_overlap = self.proximal * input_sdr.view(-1,1).float()\n",
    "active_proximal = spatial_overlap > self.perm_threshold\n",
    "# count sum synapses per column\n",
    "total_proximal = torch.sum(active_proximal, dim=0)\n",
    "# select topk columns\n",
    "kthvalue = self.num_columns - self.k\n",
    "vals, _ = torch.kthvalue(total_proximal, kthvalue)\n",
    "# selected columns as a binary masl\n",
    "selected_cols = (total_proximal > vals.view(-1,1)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select permanences above threshold\n",
    "active_distal = self.distal > self.perm_threshold\n",
    "# sum them per cell - have a list of cells which are active per column\n",
    "total_distal = torch.sum(active_distal, dim=0).float()\n",
    "# reshape them into a format of column x cell\n",
    "distal_cells = total_distal.view(self.num_columns, self.num_cells)\n",
    "# pick the top1, per column - some might be zero, so I will add some random component\n",
    "epsilon = torch.abs(torch.rand(distal_cells.shape)) * 0.001\n",
    "distal_cells += epsilon\n",
    "#\n",
    "vals, indices = torch.kthvalue(distal_cells, 1)\n",
    "# predictive cells include even the ones bursting\n",
    "predictive_cells = (distal_cells > vals.view(-1,1)).squeeze()\n",
    "# predictive cols as a mask\n",
    "predictive_cols = vals > 0.001\n",
    "# fired cells doesn't include bursting cells\n",
    "firing_cells = predictive_cells & predictive_cols.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 1, 1, 1, 3, 1])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_distal.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 1, 1, 1, 3, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_distal.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.7212e-05, 1.0005e+00],\n",
       "        [2.0000e+00, 1.0004e+00],\n",
       "        [1.0005e+00, 1.0009e+00],\n",
       "        [3.0004e+00, 1.0007e+00]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distal_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.7212e-05],\n",
       "        [1.0004e+00],\n",
       "        [1.0005e+00],\n",
       "        [1.0007e+00]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only cells that actually fired\n",
    "predictive_cells & predictive_cols.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_overlap = predictive_cols & selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.7212e-05, 1.0005e+00],\n",
       "        [2.0000e+00, 1.0004e+00],\n",
       "        [1.0005e+00, 1.0009e+00],\n",
       "        [3.0004e+00, 1.0007e+00]])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distal_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0005, 1.0009]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distal_cells[temporal_overlap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increase_cells = predictive_cells & temporal_overlap.view(-1,1)\n",
    "increase_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firing_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrease_cells = firing_cells & (temporal_overlap.view(-1,1) == 0)\n",
    "decrease_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0500, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increase = (selected_cells.view(-1).float() * self.perm_increase).view(1, -1)\n",
    "increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4286, 0.6102, 0.5415, 0.0000, 0.0000, 0.5585, 0.3436],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2902, 0.0000, 0.0000, 0.0000, 0.4090, 0.0000, 0.0000, 0.4200],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6527, 0.0000, 0.3823],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3541, 0.0000, 0.0000, 0.5452, 0.5590],\n",
       "        [0.4373, 0.4916, 0.6383, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4611, 0.4999, 0.0000, 0.4672],\n",
       "        [0.0000, 0.5166, 0.4872, 0.4154, 0.5270, 0.4588, 0.6296, 0.0000]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4286, 0.6102, 0.5415, 0.0000, 0.0000, 0.5585, 0.3436],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2902, 0.0000, 0.0000, 0.0000, 0.4090, 0.0000, 0.0000, 0.4200],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7027, 0.0000, 0.3823],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3541, 0.0000, 0.0000, 0.5452, 0.5590],\n",
       "        [0.4373, 0.4916, 0.6383, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4611, 0.5499, 0.0000, 0.4672],\n",
       "        [0.0000, 0.5166, 0.4872, 0.4154, 0.5270, 0.5088, 0.6296, 0.0000]])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mask = (self.distal > 0).float()\n",
    "new_distal = (self.distal + increase) * zero_mask\n",
    "new_distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0500, 0.0000, 0.0000, 0.0000, 0.0500, 0.0000]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrease = (decrease_cells.view(-1).float() * self.perm_increase).view(1, -1)\n",
    "decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4286, 0.5602, 0.5415, 0.0000, 0.0000, 0.5085, 0.3436],\n",
       "        [0.0000, 0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, 0.0000],\n",
       "        [0.2902, 0.0000, -0.0000, 0.0000, 0.4090, 0.0000, -0.0000, 0.4200],\n",
       "        [0.0000, 0.0000, -0.0000, 0.0000, 0.0000, 0.7027, -0.0000, 0.3823],\n",
       "        [0.0000, 0.0000, -0.0000, 0.3541, 0.0000, 0.0000, 0.4952, 0.5590],\n",
       "        [0.4373, 0.4916, 0.5883, 0.0000, 0.0000, 0.0000, -0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, -0.0000, 0.0000, 0.4611, 0.5499, -0.0000, 0.4672],\n",
       "        [0.0000, 0.5166, 0.4372, 0.4154, 0.5270, 0.5088, 0.5796, 0.0000]])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decrease the ones that fired, but no overlap\n",
    "new_distal = (self.distal +increase - decrease) * zero_mask\n",
    "new_distal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pooler import TemporalPooler\n",
    "pooler = TemporalPooler(input_size=3, num_columns=4, k_percent=.99, \n",
    "                        num_cells=2, perm_increase=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5226, 0.0000, 0.6645, 0.4356, 0.5554, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4869, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5971, 0.6036, 0.0000, 0.6770],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6075, 0.0000],\n",
       "        [0.0000, 0.6333, 0.0000, 0.0000, 0.6789, 0.0000, 0.6411, 0.5441],\n",
       "        [0.3922, 0.4993, 0.4708, 0.5636, 0.0000, 0.0000, 0.0000, 0.5758],\n",
       "        [0.0000, 0.4933, 0.4392, 0.4946, 0.0000, 0.4711, 0.4217, 0.0000]])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooler.distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "\n",
      "After\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sequence = [[0,0,1], [1,1,0], [0,0,0], [1,1,1], [1,1,0]]\n",
    "sequence = [torch.tensor(i) for i in sequence]\n",
    "\n",
    "print(\"\\nBefore\")\n",
    "for i in sequence:\n",
    "    a,b,c = pooler.forward(i)\n",
    "\n",
    "for _ in range(1000):\n",
    "    for i in sequence:\n",
    "        a,b,c = pooler.forward(i, learning=True)\n",
    "\n",
    "print(\"\\nAfter\")\n",
    "for i in sequence:\n",
    "    a,b,c = pooler.forward(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3226, 0.0000, 0.6645, 0.2356, 0.5554, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4869, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3971, 0.6036, 0.0000, 0.4770],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6075, 0.0000],\n",
       "        [0.0000, 0.4333, 0.0000, 0.0000, 0.4789, 0.0000, 0.6411, 0.3441],\n",
       "        [0.3922, 0.2993, 0.4708, 0.5636, 0.0000, 0.0000, 0.0000, 0.3758],\n",
       "        [0.0000, 0.2933, 0.4392, 0.4946, 0.0000, 0.4711, 0.4217, 0.0000]])"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooler.distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
